<div class="page-content">
  <h1>Natural user interface, final project (2011)</h1>
  <p>
    The goal for this porject was to create an application that allow users to modify 3D objects in the space by using hand gestures.
    To do this, we used the Microsoft Kinect device and OpenNI framework. With them, we were able to capture the position in the space of the hands of the person in front of the Kinect.
    Then, we defined simple rules over the position of the hands that allowed us to recognize simple gestures.
    The gestures recognized were then translated to actions in the application like move, scale or rotate the 3D objects.
  </p>

  <div class="page-content--img" nz-row nzType="flex" nzJustify="center">
    <div nz-col>
      <img src="assets/img/nui/gestures.png"/>
      <p>Recognized gestures</p>
    </div>
  </div>

  <div class="page-content--img" nz-row nzType="flex" nzJustify="center">
    <div nz-col>
      <iframe
        width="560"
        height="315"
        src="https://www.youtube.com/embed/UHh2xo0mxr8"
        frameborder="0"
        allowfullscreen>
      </iframe>
    </div>
  </div>

  <h2>Devices and technologies used</h2>
  <div class="bullets">
    <p><nz-badge nzStatus="success" nzText="Microsoft Kinect device for the 3D joint carpture"></nz-badge></p>
    <p><nz-badge nzStatus="success" nzText="OpenNI framework"></nz-badge></p>    
    <p><nz-badge nzStatus="success" nzText="Unity3D"></nz-badge></p>    
  </div>
  
  <h2>Source code</h2>
  <div class="bullets">
    <p><nz-badge nzStatus="processing"></nz-badge><a href="https://github.com/rsibanez89/natural-user-interface">https://github.com/rsibanez89/natural-user-interface</a></p> 
  </div>
</div>